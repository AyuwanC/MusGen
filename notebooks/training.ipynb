{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "1. Build model architecture\n",
    "2. Train on processed data\n",
    "3. Monitor training progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of 'src' to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 05:44:28.138667: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-10 05:44:28.138741: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-10 05:44:28.141877: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-10 05:44:28.155323: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-10 05:44:29.069627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13153294717933076620\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2279079936\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16862467915952732780\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 05:44:30.349257: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-10 05:44:30.390912: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-10 05:44:30.393721: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-10 05:44:30.529883: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-10 05:44:30.531718: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-10 05:44:30.533337: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-10 05:44:30.534906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 2173 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No full model found. Building from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 14:54:30.998576: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 14:54:31.000427: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 14:54:31.002106: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 14:54:31.003949: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 14:54:31.005765: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 14:54:31.007446: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 14:54:31.009072: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 14:54:31.010634: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 14:54:31.012245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2173 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-07-09 14:54:32.398175: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 249080064 exceeds 10% of free system memory.\n",
      "2025-07-09 14:54:32.737335: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 249080064 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1752053075.573919   14934 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 3050 Laptop GPU\" frequency: 1057 num_cores: 16 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 1572864 shared_memory_size_per_multiprocessor: 102400 memory_size: 2279079936 bandwidth: 176032000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2025-07-09 14:54:35.921680: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-07-09 14:54:36.779354: I external/local_xla/xla/service/service.cc:168] XLA service 0x760b6c2dd140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-07-09 14:54:36.779387: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-07-09 14:54:36.789791: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752053076.935306   15026 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10136/10136 [==============================] - ETA: 0s - loss: 4.1462 - pitch_loss: 3.7589 - step_loss: 0.2047 - duration_loss: 0.1826 - pitch_accuracy: 0.0456"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1752053345.193126   14934 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 3050 Laptop GPU\" frequency: 1057 num_cores: 16 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 1572864 shared_memory_size_per_multiprocessor: 102400 memory_size: 2279079936 bandwidth: 176032000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.95358, saving model to ../output/model_weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayuwan/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 3.95358, saving model to ../output/model_full.h5\n",
      "10136/10136 [==============================] - 297s 29ms/step - loss: 4.1462 - pitch_loss: 3.7589 - step_loss: 0.2047 - duration_loss: 0.1826 - pitch_accuracy: 0.0456 - val_loss: 3.9536 - val_pitch_loss: 3.6818 - val_step_loss: 0.1687 - val_duration_loss: 0.1031 - val_pitch_accuracy: 0.0511\n",
      "Epoch 2/50\n",
      "10135/10136 [============================>.] - ETA: 0s - loss: 3.8912 - pitch_loss: 3.6248 - step_loss: 0.1444 - duration_loss: 0.1220 - pitch_accuracy: 0.0635\n",
      "Epoch 2: val_loss improved from 3.95358 to 3.82973, saving model to ../output/model_weights.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 3.95358 to 3.82973, saving model to ../output/model_full.h5\n",
      "10136/10136 [==============================] - 389s 38ms/step - loss: 3.8912 - pitch_loss: 3.6248 - step_loss: 0.1444 - duration_loss: 0.1220 - pitch_accuracy: 0.0635 - val_loss: 3.8297 - val_pitch_loss: 3.6134 - val_step_loss: 0.1168 - val_duration_loss: 0.0994 - val_pitch_accuracy: 0.0658\n",
      "Epoch 3/50\n",
      "10135/10136 [============================>.] - ETA: 0s - loss: 3.7834 - pitch_loss: 3.5303 - step_loss: 0.1360 - duration_loss: 0.1171 - pitch_accuracy: 0.0817\n",
      "Epoch 3: val_loss improved from 3.82973 to 3.75605, saving model to ../output/model_weights.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 3.82973 to 3.75605, saving model to ../output/model_full.h5\n",
      "10136/10136 [==============================] - 390s 39ms/step - loss: 3.7834 - pitch_loss: 3.5303 - step_loss: 0.1360 - duration_loss: 0.1171 - pitch_accuracy: 0.0817 - val_loss: 3.7561 - val_pitch_loss: 3.5472 - val_step_loss: 0.1139 - val_duration_loss: 0.0949 - val_pitch_accuracy: 0.0788\n",
      "Epoch 4/50\n",
      "10136/10136 [==============================] - ETA: 0s - loss: 3.6834 - pitch_loss: 3.4390 - step_loss: 0.1313 - duration_loss: 0.1132 - pitch_accuracy: 0.0993\n",
      "Epoch 4: val_loss did not improve from 3.75605\n",
      "\n",
      "Epoch 4: val_loss did not improve from 3.75605\n",
      "10136/10136 [==============================] - 460s 45ms/step - loss: 3.6834 - pitch_loss: 3.4390 - step_loss: 0.1313 - duration_loss: 0.1132 - pitch_accuracy: 0.0993 - val_loss: 3.7593 - val_pitch_loss: 3.5412 - val_step_loss: 0.1172 - val_duration_loss: 0.1010 - val_pitch_accuracy: 0.0839\n",
      "Epoch 5/50\n",
      "10136/10136 [==============================] - ETA: 0s - loss: 3.5796 - pitch_loss: 3.3429 - step_loss: 0.1277 - duration_loss: 0.1089 - pitch_accuracy: 0.1183\n",
      "Epoch 5: val_loss improved from 3.75605 to 3.71257, saving model to ../output/model_weights.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 3.75605 to 3.71257, saving model to ../output/model_full.h5\n",
      "10136/10136 [==============================] - 560s 55ms/step - loss: 3.5796 - pitch_loss: 3.3429 - step_loss: 0.1277 - duration_loss: 0.1089 - pitch_accuracy: 0.1183 - val_loss: 3.7126 - val_pitch_loss: 3.5107 - val_step_loss: 0.1100 - val_duration_loss: 0.0919 - val_pitch_accuracy: 0.0921\n",
      "Epoch 6/50\n",
      "10136/10136 [==============================] - ETA: 0s - loss: 3.4781 - pitch_loss: 3.2466 - step_loss: 0.1248 - duration_loss: 0.1067 - pitch_accuracy: 0.1380\n",
      "Epoch 6: val_loss improved from 3.71257 to 3.71071, saving model to ../output/model_weights.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 3.71257 to 3.71071, saving model to ../output/model_full.h5\n",
      "10136/10136 [==============================] - 463s 46ms/step - loss: 3.4781 - pitch_loss: 3.2466 - step_loss: 0.1248 - duration_loss: 0.1067 - pitch_accuracy: 0.1380 - val_loss: 3.7107 - val_pitch_loss: 3.4978 - val_step_loss: 0.1141 - val_duration_loss: 0.0988 - val_pitch_accuracy: 0.0974\n",
      "Epoch 7/50\n",
      "10135/10136 [============================>.] - ETA: 0s - loss: 3.3778 - pitch_loss: 3.1529 - step_loss: 0.1217 - duration_loss: 0.1032 - pitch_accuracy: 0.1566\n",
      "Epoch 7: val_loss did not improve from 3.71071\n",
      "\n",
      "Epoch 7: val_loss did not improve from 3.71071\n",
      "10136/10136 [==============================] - 540s 53ms/step - loss: 3.3778 - pitch_loss: 3.1529 - step_loss: 0.1217 - duration_loss: 0.1032 - pitch_accuracy: 0.1566 - val_loss: 3.7162 - val_pitch_loss: 3.5120 - val_step_loss: 0.1111 - val_duration_loss: 0.0930 - val_pitch_accuracy: 0.1026\n",
      "Epoch 8/50\n",
      "10134/10136 [============================>.] - ETA: 0s - loss: 3.2846 - pitch_loss: 3.0642 - step_loss: 0.1193 - duration_loss: 0.1011 - pitch_accuracy: 0.1755\n",
      "Epoch 8: val_loss did not improve from 3.71071\n",
      "\n",
      "Epoch 8: val_loss did not improve from 3.71071\n",
      "10136/10136 [==============================] - 282s 28ms/step - loss: 3.2846 - pitch_loss: 3.0642 - step_loss: 0.1193 - duration_loss: 0.1011 - pitch_accuracy: 0.1755 - val_loss: 3.7261 - val_pitch_loss: 3.5254 - val_step_loss: 0.1090 - val_duration_loss: 0.0917 - val_pitch_accuracy: 0.1031\n",
      "Epoch 9/50\n",
      "10135/10136 [============================>.] - ETA: 0s - loss: 3.1939 - pitch_loss: 2.9789 - step_loss: 0.1164 - duration_loss: 0.0985 - pitch_accuracy: 0.1938\n",
      "Epoch 9: val_loss did not improve from 3.71071\n",
      "\n",
      "Epoch 9: val_loss did not improve from 3.71071\n",
      "10136/10136 [==============================] - 274s 27ms/step - loss: 3.1939 - pitch_loss: 2.9789 - step_loss: 0.1164 - duration_loss: 0.0985 - pitch_accuracy: 0.1938 - val_loss: 3.7275 - val_pitch_loss: 3.5260 - val_step_loss: 0.1100 - val_duration_loss: 0.0915 - val_pitch_accuracy: 0.1103\n",
      "Epoch 10/50\n",
      "10135/10136 [============================>.] - ETA: 0s - loss: 3.1096 - pitch_loss: 2.8993 - step_loss: 0.1143 - duration_loss: 0.0960 - pitch_accuracy: 0.2117\n",
      "Epoch 10: val_loss did not improve from 3.71071\n",
      "\n",
      "Epoch 10: val_loss did not improve from 3.71071\n",
      "10136/10136 [==============================] - 272s 27ms/step - loss: 3.1096 - pitch_loss: 2.8993 - step_loss: 0.1143 - duration_loss: 0.0960 - pitch_accuracy: 0.2117 - val_loss: 3.7669 - val_pitch_loss: 3.5675 - val_step_loss: 0.1097 - val_duration_loss: 0.0897 - val_pitch_accuracy: 0.1066\n",
      "Epoch 11/50\n",
      "10135/10136 [============================>.] - ETA: 0s - loss: 3.0296 - pitch_loss: 2.8241 - step_loss: 0.1118 - duration_loss: 0.0937 - pitch_accuracy: 0.2285\n",
      "Epoch 11: val_loss did not improve from 3.71071\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 3.71071\n",
      "10136/10136 [==============================] - 271s 27ms/step - loss: 3.0296 - pitch_loss: 2.8241 - step_loss: 0.1118 - duration_loss: 0.0937 - pitch_accuracy: 0.2285 - val_loss: 3.8141 - val_pitch_loss: 3.6105 - val_step_loss: 0.1111 - val_duration_loss: 0.0925 - val_pitch_accuracy: 0.1084\n",
      "Epoch 11: early stopping\n",
      "Training complete! Model and weights saved.\n"
     ]
    }
   ],
   "source": [
    "from src.train import train\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Generate Sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 749ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1752106226.588366   78518 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce RTX 3050 Laptop GPU\" frequency: 1057 num_cores: 16 environment { key: \"architecture\" value: \"8.6\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 1572864 shared_memory_size_per_multiprocessor: 102400 memory_size: 2279079936 bandwidth: 176032000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "from src.generate import generate_music, events_to_midi, get_seed\n",
    "import numpy as np\n",
    "\n",
    "# seed = np.random.randint(0, 128, size=(32, 3))\n",
    "seed = get_seed(seed_type=\"chordal\") # random, ascending, chordal, rhythmic\n",
    "generated = generate_music(seed, length=150)\n",
    "events_to_midi(generated, \"../outputs/generated/sample.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ayuwan/MusGen/notebooks/../src/control.py\", line 2, in <module>\n",
      "    from generate import generate_music, events_to_midi, get_seed\n",
      "  File \"/home/ayuwan/MusGen/src/generate.py\", line 4, in <module>\n",
      "    from ..src.model import build_model\n",
      "ImportError: attempted relative import with no known parent package\n"
     ]
    }
   ],
   "source": [
    "!python3 ../src/control.py --key G --scale blues --temp 1.2 --density 0.8 --output blues.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
